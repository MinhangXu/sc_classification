{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b030aea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scanpy as sc\n",
    "import statsmodels.formula.api as smf\n",
    "from sklearn.model_selection import LeaveOneGroupOut\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score, pairwise_distances\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d838d187",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Initial Data Loading and Setup (as before) ---\n",
    "adata = sc.read_h5ad('/home/minhang/mds_project/data/cohort_adata/multiVI_model/adata_multivi_corrected_rna.h5ad')\n",
    "adata_preSCT = adata[adata.obs['timepoint_type'] == 'preSCT'].copy()\n",
    "\n",
    "latent_df = pd.DataFrame(\n",
    "    adata_preSCT.obsm['X_multivi'],\n",
    "    columns=[f'LatentFactor_{i+1}' for i in range(23)]\n",
    ")\n",
    "latent_df['sample'] = adata_preSCT.obs['sample'].values\n",
    "latent_df['patient'] = adata_preSCT.obs['patient'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "32db1c6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Generating Feature Matrices ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1009055/1567564239.py:5: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  summary_matrix_mean = latent_df.groupby('sample').mean(numeric_only=True)\n",
      "/tmp/ipykernel_1009055/1567564239.py:8: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  summary_matrix_l2 = latent_df.groupby('sample').std(numeric_only=True)\n",
      "/tmp/ipykernel_1009055/1567564239.py:15: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  summary_matrix_l1 = latent_df.groupby('sample')[numeric_cols].agg(l1_spread)\n"
     ]
    }
   ],
   "source": [
    "# --- Step 1: Feature Engineering - Create 3 Summary Matrices ---\n",
    "\n",
    "print(\"--- Generating Feature Matrices ---\")\n",
    "# Hypothesis 1: Average Cellular State (Mean)\n",
    "summary_matrix_mean = latent_df.groupby('sample').mean(numeric_only=True)\n",
    "\n",
    "# Hypothesis 2: Cellular Heterogeneity (L2 Spread - Standard Deviation)\n",
    "summary_matrix_l2 = latent_df.groupby('sample').std(numeric_only=True)\n",
    "\n",
    "# Hypothesis 3: Cellular Heterogeneity (L1 Spread - Mean Absolute Deviation from the median)\n",
    "def l1_spread(series):\n",
    "    return np.mean(np.abs(series - series.median()))\n",
    "\n",
    "numeric_cols = [f'LatentFactor_{i+1}' for i in range(23)]\n",
    "summary_matrix_l1 = latent_df.groupby('sample')[numeric_cols].agg(l1_spread)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "63a49bf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean matrix shape: (19, 23)\n",
      "L2 Spread (std) matrix shape: (19, 23)\n",
      "L1 Spread (mad) matrix shape: (19, 23)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Mean matrix shape: {summary_matrix_mean.shape}\")\n",
    "print(f\"L2 Spread (std) matrix shape: {summary_matrix_l2.shape}\")\n",
    "print(f\"L1 Spread (mad) matrix shape: {summary_matrix_l1.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bd55d7d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_prognostic_analysis(feature_matrix, sample_info, responder_map):\n",
    "    \"\"\"\n",
    "    Runs a full LOGO cross-validation and bootstrap analysis for a given feature set.\n",
    "    \"\"\"\n",
    "    # Add patient and status info to the feature matrix\n",
    "    feature_matrix = feature_matrix.join(sample_info[['patient']])\n",
    "    feature_matrix['status'] = feature_matrix['patient'].map(responder_map)\n",
    "    feature_matrix.dropna(inplace=True) \n",
    "\n",
    "    # Prepare data for scikit-learn\n",
    "    X = feature_matrix.drop(columns=['patient', 'status'])\n",
    "    y = (feature_matrix['status'] == 'Non-Responder').astype(int)\n",
    "    groups = feature_matrix['patient']\n",
    "\n",
    "    # Scale features\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "    # Setup the model and Leave-One-Group-Out cross-validator\n",
    "    model = LogisticRegression(penalty='l1', solver='liblinear', C=0.5, class_weight='balanced')\n",
    "    logo = LeaveOneGroupOut()\n",
    "\n",
    "    # Store predictions from LOGO\n",
    "    y_true_logo = []\n",
    "    y_pred_probs_logo = []\n",
    "\n",
    "    for train_index, test_index in logo.split(X_scaled, y, groups):\n",
    "        X_train, X_test = X_scaled[train_index], X_scaled[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "        \n",
    "        model.fit(X_train, y_train)\n",
    "        pred_prob = model.predict_proba(X_test)[:, 1]\n",
    "        \n",
    "        y_true_logo.extend(y_test.values)\n",
    "        y_pred_probs_logo.extend(pred_prob)\n",
    "\n",
    "    # Calculate the overall AUROC from all LOGO predictions\n",
    "    auroc_pilot = roc_auc_score(y_true_logo, y_pred_probs_logo)\n",
    "\n",
    "    # Calculate Standard Error using bootstrapping\n",
    "    n_bootstraps = 1000\n",
    "    bootstrapped_aurocs = []\n",
    "    for _ in range(n_bootstraps):\n",
    "        indices = np.random.choice(len(y_true_logo), size=len(y_true_logo), replace=True)\n",
    "        if len(np.unique(np.array(y_true_logo)[indices])) < 2:\n",
    "            continue\n",
    "        resampled_auroc = roc_auc_score(np.array(y_true_logo)[indices], np.array(y_pred_probs_logo)[indices])\n",
    "        bootstrapped_aurocs.append(resampled_auroc)\n",
    "\n",
    "    se_auroc_pilot = np.std(bootstrapped_aurocs)\n",
    "    \n",
    "    return {\"auroc\": auroc_pilot, \"se\": se_auroc_pilot}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a504b00e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Step 3: Run the Analysis for Each Hypothesis ---\n",
    "\n",
    "sample_info = latent_df[['sample', 'patient']].drop_duplicates().set_index('sample')\n",
    "responder_map = {\n",
    "    'P10': 'Responder', 'P11': 'Responder', 'P12': 'Responder',\n",
    "    'P09': 'Non-Responder', 'P13': 'Non-Responder', 'P04': 'Non-Responder',\n",
    "    'P05': 'Non-Responder', 'P06': 'Non-Responder', 'P07': 'Non-Responder',\n",
    "    'P08': 'Non-Responder', 'P02': 'Non-Responder', 'P01': 'Non-Responder'\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1246e5d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Running Analyses ---\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- Running Analyses ---\")\n",
    "results_mean = run_prognostic_analysis(summary_matrix_mean, sample_info, responder_map)\n",
    "results_l2 = run_prognostic_analysis(summary_matrix_l2, sample_info, responder_map)\n",
    "results_l1 = run_prognostic_analysis(summary_matrix_l1, sample_info, responder_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3cd2d6af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Comparative Results ---\n",
      "                    auroc      se  95% CI Half-Width\n",
      "Mean State         0.9167  0.0704             0.1380\n",
      "L2 Spread (StDev)  0.2500  0.1114             0.2184\n",
      "L1 Spread (MAD)    0.7708  0.1374             0.2693\n"
     ]
    }
   ],
   "source": [
    "# --- Step 4: Display Results ---\n",
    "\n",
    "print(\"\\n--- Comparative Results ---\")\n",
    "results_df = pd.DataFrame({\n",
    "    'Mean State': results_mean,\n",
    "    'L2 Spread (StDev)': results_l2,\n",
    "    'L1 Spread (MAD)': results_l1\n",
    "}).T\n",
    "results_df['95% CI Half-Width'] = results_df['se'] * 1.96\n",
    "\n",
    "print(results_df.round(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9252a96d",
   "metadata": {},
   "source": [
    "Cell type based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e16a8050",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_cols = [f'LatentFactor_{i+1}' for i in range(23)]\n",
    "latent_df = pd.DataFrame(adata_preSCT.obsm['X_multivi'], columns=numeric_cols)\n",
    "latent_df['sample'] = adata_preSCT.obs['sample'].values\n",
    "latent_df['patient'] = adata_preSCT.obs['patient'].values\n",
    "latent_df['cell_type'] = adata_preSCT.obs['predicted.annotation'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b6126d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_prognostic_analysis(feature_matrix, sample_info, responder_map):\n",
    "    \"\"\"\n",
    "    Runs a full LOGO cross-validation and bootstrap analysis for a given feature set.\n",
    "    Handles scaling and NaN imputation correctly inside the CV loop.\n",
    "    \"\"\"\n",
    "    feature_matrix = feature_matrix.join(sample_info[['patient']])\n",
    "    feature_matrix['status'] = feature_matrix['patient'].map(responder_map)\n",
    "    feature_matrix.dropna(inplace=True, subset=['status'])\n",
    "\n",
    "    X = feature_matrix.drop(columns=['patient', 'status'])\n",
    "    y = (feature_matrix['status'] == 'Non-Responder').astype(int)\n",
    "    groups = feature_matrix['patient']\n",
    "\n",
    "    model = LogisticRegression(penalty='l1', solver='liblinear', C=0.5, class_weight='balanced')\n",
    "    logo = LeaveOneGroupOut()\n",
    "\n",
    "    y_true_logo, y_pred_probs_logo = [], []\n",
    "    \n",
    "    for train_index, test_index in logo.split(X, y, groups):\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "        \n",
    "        # THE FIX: Scaler is now INSIDE the loop\n",
    "        scaler = StandardScaler()\n",
    "        \n",
    "        # Fit the scaler ONLY on the training data\n",
    "        X_train_scaled = scaler.fit_transform(X_train)\n",
    "        # Transform the test data using the scaler fitted on the training data\n",
    "        X_test_scaled = scaler.transform(X_test)\n",
    "        \n",
    "        # THE FIX PART 2: Handle NaNs created by zero-variance columns\n",
    "        # Replace any NaNs that resulted from scaling with 0\n",
    "        X_train_scaled = np.nan_to_num(X_train_scaled)\n",
    "        X_test_scaled = np.nan_to_num(X_test_scaled)\n",
    "        \n",
    "        model.fit(X_train_scaled, y_train)\n",
    "        pred_prob = model.predict_proba(X_test_scaled)[:, 1]\n",
    "        \n",
    "        y_true_logo.extend(y_test.values)\n",
    "        y_pred_probs_logo.extend(pred_prob)\n",
    "\n",
    "    auroc_pilot = roc_auc_score(y_true_logo, y_pred_probs_logo)\n",
    "\n",
    "    n_bootstraps = 1000\n",
    "    bootstrapped_aurocs = []\n",
    "    for _ in range(n_bootstraps):\n",
    "        indices = np.random.choice(len(y_true_logo), size=len(y_true_logo), replace=True)\n",
    "        if len(np.unique(np.array(y_true_logo)[indices])) < 2:\n",
    "            continue\n",
    "        resampled_auroc = roc_auc_score(np.array(y_true_logo)[indices], np.array(y_pred_probs_logo)[indices])\n",
    "        bootstrapped_aurocs.append(resampled_auroc)\n",
    "\n",
    "    se_auroc_pilot = np.std(bootstrapped_aurocs)\n",
    "    return {\"auroc\": auroc_pilot, \"se\": se_auroc_pilot}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0a2632c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Generating All Feature Matrices ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1009055/3716747900.py:6: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  summary_matrix_mean_overall = latent_df.groupby('sample')[numeric_cols].mean()\n",
      "/tmp/ipykernel_1009055/3716747900.py:7: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  summary_matrix_l2_overall = latent_df.groupby('sample')[numeric_cols].std()\n",
      "/tmp/ipykernel_1009055/3716747900.py:10: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  summary_matrix_l1_overall = latent_df.groupby('sample')[numeric_cols].agg(l1_spread_univariate)\n"
     ]
    }
   ],
   "source": [
    "# --- Step 1: Feature Engineering - Test 5 Different Hypotheses ---\n",
    "\n",
    "print(\"--- Generating All Feature Matrices ---\")\n",
    "\n",
    "# --- Overall (Global) Features ---\n",
    "summary_matrix_mean_overall = latent_df.groupby('sample')[numeric_cols].mean()\n",
    "summary_matrix_l2_overall = latent_df.groupby('sample')[numeric_cols].std()\n",
    "def l1_spread_univariate(series):\n",
    "    return np.mean(np.abs(series - series.median()))\n",
    "summary_matrix_l1_overall = latent_df.groupby('sample')[numeric_cols].agg(l1_spread_univariate)\n",
    "\n",
    "# --- Cell-Type-Specific Features (Multivariate Spread) ---\n",
    "def l2_spread_multivariate(df):\n",
    "    # Calculate the centroid (mean vector) of the cell cloud\n",
    "    centroid = df.mean(axis=0).values.reshape(1, -1)\n",
    "    # Calculate Euclidean distance from each cell to the centroid, then average\n",
    "    distances = pairwise_distances(df, centroid, metric='euclidean')\n",
    "    return np.mean(distances)\n",
    "\n",
    "def l1_spread_multivariate(df):\n",
    "    # Calculate the centroid\n",
    "    centroid = df.mean(axis=0).values.reshape(1, -1)\n",
    "    # Calculate Manhattan distance from each cell to the centroid, then average\n",
    "    distances = pairwise_distances(df, centroid, metric='manhattan')\n",
    "    return np.mean(distances)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0a0c3ee4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1009055/978590743.py:2: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  grouped = latent_df.groupby(['sample', 'cell_type'])[numeric_cols]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cell-Type L2 Spread matrix shape: (19, 13)\n",
      "Cell-Type L1 Spread matrix shape: (19, 13)\n"
     ]
    }
   ],
   "source": [
    "# Group by sample and cell_type, then apply our multivariate functions\n",
    "grouped = latent_df.groupby(['sample', 'cell_type'])[numeric_cols]\n",
    "celltype_l2_long = grouped.apply(l2_spread_multivariate)\n",
    "celltype_l1_long = grouped.apply(l1_spread_multivariate)\n",
    "\n",
    "# Unstack to get the wide format (13 features per sample)\n",
    "summary_matrix_l2_celltype = celltype_l2_long.unstack(level='cell_type')\n",
    "summary_matrix_l1_celltype = celltype_l1_long.unstack(level='cell_type')\n",
    "\n",
    "print(f\"Cell-Type L2 Spread matrix shape: {summary_matrix_l2_celltype.shape}\")\n",
    "print(f\"Cell-Type L1 Spread matrix shape: {summary_matrix_l1_celltype.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9261b033",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape after dropping NaN columns: (19, 9)\n",
      "Shape after dropping NaN columns: (19, 9)\n"
     ]
    }
   ],
   "source": [
    "celltype_l2_wide_dropped = summary_matrix_l2_celltype.dropna(axis=1)\n",
    "print(f\"Shape after dropping NaN columns: {celltype_l2_wide_dropped.shape}\")\n",
    "\n",
    "celltype_l1_wide_dropped = summary_matrix_l1_celltype.dropna(axis=1)\n",
    "print(f\"Shape after dropping NaN columns: {celltype_l1_wide_dropped.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4bb5102c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Running All Analyses ---\n",
      "\n",
      "--- Final Comparative Results ---\n",
      "                                     auroc      se  95% CI Half-Width\n",
      "Cell-Type L1 Spread (Multivariate)  0.1458  0.1093             0.2143\n",
      "Cell-Type L2 Spread (Multivariate)  0.0417  0.0571             0.1119\n"
     ]
    }
   ],
   "source": [
    "sample_info = latent_df[['sample', 'patient']].drop_duplicates().set_index('sample')\n",
    "responder_map = {\n",
    "    'P10': 'Responder', 'P11': 'Responder', 'P12': 'Responder',\n",
    "    'P09': 'Non-Responder', 'P13': 'Non-Responder', 'P04': 'Non-Responder',\n",
    "    'P05': 'Non-Responder', 'P06': 'Non-Responder', 'P07': 'Non-Responder',\n",
    "    'P08': 'Non-Responder', 'P02': 'Non-Responder', 'P01': 'Non-Responder'\n",
    "}\n",
    "\n",
    "print(\"\\n--- Running All Analyses ---\")\n",
    "# Overall metrics\n",
    "#results_mean_overall = run_prognostic_analysis(summary_matrix_mean_overall, sample_info, responder_map)\n",
    "#results_l2_overall = run_prognostic_analysis(summary_matrix_l2_overall, sample_info, responder_map)\n",
    "#results_l1_overall = run_prognostic_analysis(summary_matrix_l1_overall, sample_info, responder_map)\n",
    "# Cell-type-specific metrics\n",
    "results_l2_celltype = run_prognostic_analysis(celltype_l2_wide_dropped, sample_info, responder_map)\n",
    "results_l1_celltype = run_prognostic_analysis(celltype_l1_wide_dropped, sample_info, responder_map)\n",
    "\n",
    "# --- Step 3: Display Final Comparative Results ---\n",
    "\n",
    "print(\"\\n--- Final Comparative Results ---\")\n",
    "final_results_df = pd.DataFrame({\n",
    "    #'Overall Mean State': results_mean_overall,\n",
    "    #'Overall L1 Spread (Univariate)': results_l1_overall,\n",
    "    #'Overall L2 Spread (Univariate)': results_l2_overall,\n",
    "    'Cell-Type L1 Spread (Multivariate)': results_l1_celltype,\n",
    "    'Cell-Type L2 Spread (Multivariate)': results_l2_celltype,\n",
    "}).T\n",
    "final_results_df['95% CI Half-Width'] = final_results_df['se'] * 1.96\n",
    "\n",
    "print(final_results_df.round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fe4303e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mds_responder_analysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
