{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a597ee2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/minhang/miniconda3/envs/scvi-env/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# In a Jupyter Notebook cell\n",
    "import scvi\n",
    "import torch\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import anndata\n",
    "import scanpy as sc # For reading AnnData\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d8a0c359",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch CUDA available: True\n",
      "Number of CUDA devices: 8\n",
      "PyTorch CUDA version: 11.8\n",
      "Set scvi.settings.dl_num_workers to: 0\n",
      "Loading original AnnData object from: /home/minhang/mds_project/data/cohort_adata/multiVI_model/adata.h5ad\n",
      "Original AnnData loaded: (192149, 335386)\n",
      "Setting up original AnnData for MULTIVI model...\n",
      "\u001b[34mINFO    \u001b[0m Using column names from columns of adata.obsm\u001b[1m[\u001b[0m\u001b[32m'ADT'\u001b[0m\u001b[1m]\u001b[0m                                                      \n",
      "Original AnnData setup complete.\n",
      "Initializing MULTIVI model shell...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">MultiVI Model with the following params: \n",
       "n_genes: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">36601</span>, n_regions: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">298785</span>, n_proteins: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">170</span>, n_hidden: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">546</span>, n_latent: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">23</span>, n_layers_encoder: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>, \n",
       "n_layers_decoder: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>, dropout_rate: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1</span>, latent_distribution: normal, deep injection: <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>, gene_likelihood: zinb, \n",
       "gene_dispersion:gene, Mod.Weights: equal, Mod.Penalty: Jeffreys, protein_dispersion: protein\n",
       "Training status: Not Trained\n",
       "</pre>\n"
      ],
      "text/plain": [
       "MultiVI Model with the following params: \n",
       "n_genes: \u001b[1;36m36601\u001b[0m, n_regions: \u001b[1;36m298785\u001b[0m, n_proteins: \u001b[1;36m170\u001b[0m, n_hidden: \u001b[1;36m546\u001b[0m, n_latent: \u001b[1;36m23\u001b[0m, n_layers_encoder: \u001b[1;36m2\u001b[0m, \n",
       "n_layers_decoder: \u001b[1;36m2\u001b[0m, dropout_rate: \u001b[1;36m0.1\u001b[0m, latent_distribution: normal, deep injection: \u001b[3;91mFalse\u001b[0m, gene_likelihood: zinb, \n",
       "gene_dispersion:gene, Mod.Weights: equal, Mod.Penalty: Jeffreys, protein_dispersion: protein\n",
       "Training status: Not Trained\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model shell created. Inferred params: \n",
      "Loading model state from: /home/minhang/mds_project/data/cohort_adata/multiVI_model/model.pt\n",
      "Model state loaded.\n",
      "Model moved to device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(f\"PyTorch CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"Number of CUDA devices: {torch.cuda.device_count()}\")\n",
    "    print(f\"PyTorch CUDA version: {torch.version.cuda}\")\n",
    "else:\n",
    "    print(\"CRITICAL ERROR: CUDA not available. This notebook requires GPU.\")\n",
    "    # You might want to stop execution if no GPU\n",
    "\n",
    "# --- scvi-tools Settings ---\n",
    "# Set dl_num_workers (e.g., to 0 for simplicity in notebook debugging, or 2 if preferred)\n",
    "scvi.settings.dl_num_workers = 0\n",
    "print(f\"Set scvi.settings.dl_num_workers to: {scvi.settings.dl_num_workers}\")\n",
    "\n",
    "# --- File Paths ---\n",
    "base_dir = '/home/minhang/mds_project/data/cohort_adata/multiVI_model'\n",
    "original_adata_path = os.path.join(base_dir, 'adata.h5ad')\n",
    "model_pt_path = os.path.join(base_dir, 'model.pt')\n",
    "\n",
    "# --- Load Original AnnData (for model context) ---\n",
    "print(f\"Loading original AnnData object from: {original_adata_path}\")\n",
    "adata_mvi_original = sc.read_h5ad(original_adata_path)\n",
    "adata_mvi_original.var_names_make_unique()\n",
    "print(f\"Original AnnData loaded: {adata_mvi_original.shape}\")\n",
    "\n",
    "# --- Setup AnnData for scvi-tools (using the original AnnData) ---\n",
    "print(\"Setting up original AnnData for MULTIVI model...\")\n",
    "scvi.model.MULTIVI.setup_anndata(\n",
    "    adata_mvi_original,\n",
    "    batch_key=\"Tech\",\n",
    "    protein_expression_obsm_key=\"ADT\",\n",
    "    categorical_covariate_keys=[\"sample\"]\n",
    ")\n",
    "print(\"Original AnnData setup complete.\")\n",
    "\n",
    "# --- Initialize Model Shell & Load State ---\n",
    "print(\"Initializing MULTIVI model shell...\")\n",
    "n_genes_val = (adata_mvi_original.var[\"modality\"] == \"Gene Expression\").sum()\n",
    "n_regions_val = (adata_mvi_original.var[\"modality\"] == \"peaks\").sum()\n",
    "model_shell = scvi.model.MULTIVI(\n",
    "    adata_mvi_original,\n",
    "    n_genes=n_genes_val,\n",
    "    n_regions=n_regions_val,\n",
    ")\n",
    "print(f\"Model shell created. Inferred params: {model_shell}\") # Shows n_hidden, n_latent etc.\n",
    "\n",
    "print(f\"Loading model state from: {model_pt_path}\")\n",
    "loaded_full_checkpoint = torch.load(model_pt_path, map_location='cpu', weights_only=False)\n",
    "actual_state_dict = loaded_full_checkpoint['model_state_dict']\n",
    "model_shell.module.load_state_dict(actual_state_dict)\n",
    "model_shell.is_trained_ = True\n",
    "model = model_shell # Assign to 'model'\n",
    "print(\"Model state loaded.\")\n",
    "\n",
    "# --- Move Model to GPU ---\n",
    "if torch.cuda.is_available():\n",
    "    target_device = \"cuda:0\"\n",
    "    model.to_device(target_device)\n",
    "    print(f\"Model moved to device: {model.device}\")\n",
    "else:\n",
    "    print(\"Model cannot be moved to GPU as CUDA is not available.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "45b0df1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model is on device: cuda:0. Proceeding with batch processing...\n",
      "DataLoader created. Will process one batch of size up to 128.\n",
      "\n",
      "Processing batch 1 for inspection...\n",
      "  Tensors moved to GPU.\n",
      "  Inference step complete.\n",
      "  Generative step complete.\n",
      "\n",
      "  --- Inspecting generative_outputs_dict ---\n",
      "  Top-level keys: dict_keys(['p', 'px_scale', 'px_r', 'px_rate', 'px_dropout', 'py_', 'log_pro_back_mean'])\n",
      "  --- End of inspection for this batch ---\n",
      "\n",
      "Inspection finished.\n"
     ]
    }
   ],
   "source": [
    "# Ensure model and adata_mvi_original are loaded and model is on GPU\n",
    "if 'model' not in locals() or 'adata_mvi_original' not in locals():\n",
    "    print(\"ERROR: 'model' or 'adata_mvi_original' not loaded. Please run the setup cell first.\")\n",
    "elif model.device.type != 'cuda':\n",
    "    print(\"ERROR: Model is not on CUDA device. Please move it to GPU.\")\n",
    "else:\n",
    "    print(f\"Model is on device: {model.device}. Proceeding with batch processing...\")\n",
    "\n",
    "    batch_size_inspect = 128  # Use a small batch size for quick inspection\n",
    "\n",
    "    # Create a DataLoader using the adata_mvi_original\n",
    "    inspect_scdl = model._make_data_loader(\n",
    "        adata=adata_mvi_original,\n",
    "        shuffle=False, # Keep order for consistency, though not strictly needed for key inspection\n",
    "        batch_size=batch_size_inspect,\n",
    "    )\n",
    "    print(f\"DataLoader created. Will process one batch of size up to {batch_size_inspect}.\")\n",
    "\n",
    "    with torch.no_grad():\n",
    "        model.module.eval()\n",
    "\n",
    "        for i, tensors_cpu in enumerate(inspect_scdl):\n",
    "            print(f\"\\nProcessing batch {i+1} for inspection...\")\n",
    "            \n",
    "            # 1. Manually move tensors to the model's device\n",
    "            tensors_gpu = {\n",
    "                k: v.to(model.device) if isinstance(v, torch.Tensor) else v\n",
    "                for k, v in tensors_cpu.items()\n",
    "            }\n",
    "            print(\"  Tensors moved to GPU.\")\n",
    "\n",
    "            # 2. Perform inference\n",
    "            inference_kwargs = {\"n_samples\": 1} \n",
    "            inference_inputs = model.module._get_inference_input(tensors_gpu)\n",
    "            inference_outputs = model.module.inference(**inference_inputs, **inference_kwargs)\n",
    "            print(\"  Inference step complete.\")\n",
    "            # print(f\"  Inference output keys: {inference_outputs.keys()}\") # Optional: view inference keys\n",
    "\n",
    "            # 3. Perform generation\n",
    "            generative_kwargs = {\"use_z_mean\": True} \n",
    "            generative_inputs = model.module._get_generative_input(tensors_gpu, inference_outputs)\n",
    "            generative_outputs_dict = model.module.generative(**generative_inputs, **generative_kwargs)\n",
    "            print(\"  Generative step complete.\")\n",
    "\n",
    "            # --- INSPECTION ---\n",
    "            print(\"\\n  --- Inspecting generative_outputs_dict ---\")\n",
    "            print(f\"  Top-level keys: {generative_outputs_dict.keys()}\")\n",
    "\n",
    "            if \"px\" in generative_outputs_dict:\n",
    "                print(f\"    Keys in generative_outputs_dict['px'] (for RNA): {generative_outputs_dict['px'].keys()}\")\n",
    "                if \"px_scale\" in generative_outputs_dict[\"px\"]:\n",
    "                    print(f\"      Shape of px_scale (RNA): {generative_outputs_dict['px']['px_scale'].shape}\")\n",
    "            \n",
    "            if \"py\" in generative_outputs_dict:\n",
    "                print(f\"    Keys in generative_outputs_dict['py'] (for Protein): {generative_outputs_dict['py'].keys()}\")\n",
    "                # Example: check for 'py_mean' or 'py_normalized'\n",
    "                if \"py_mean\" in generative_outputs_dict[\"py\"]:\n",
    "                     print(f\"      Shape of py_mean (Protein): {generative_outputs_dict['py']['py_mean'].shape}\")\n",
    "                if \"py_normalized\" in generative_outputs_dict[\"py\"]:\n",
    "                     print(f\"      Shape of py_normalized (Protein): {generative_outputs_dict['py']['py_normalized'].shape}\")\n",
    "\n",
    "            if \"pa\" in generative_outputs_dict:\n",
    "                print(f\"    Keys in generative_outputs_dict['pa'] (for ATAC): {generative_outputs_dict['pa'].keys()}\")\n",
    "                # Example: check for 'pa_probs'\n",
    "                if \"pa_probs\" in generative_outputs_dict[\"pa\"]:\n",
    "                    print(f\"      Shape of pa_probs (ATAC): {generative_outputs_dict['pa']['pa_probs'].shape}\")\n",
    "            \n",
    "            print(\"  --- End of inspection for this batch ---\")\n",
    "            \n",
    "            break # Process only the first batch\n",
    "\n",
    "    print(\"\\nInspection finished.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dd2b4efc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model is on device: cuda:0. Proceeding with batch processing for inspection...\n",
      "DataLoader created. Will process one batch of size up to 128.\n",
      "Expected number of proteins: 170\n",
      "Expected number of regions (peaks): 298785\n",
      "\n",
      "Processing batch 1 for inspection...\n",
      "  Tensors moved to GPU.\n",
      "  Inference step complete.\n",
      "  Generative step complete.\n",
      "\n",
      "  --- Inspecting generative_outputs_dict ---\n",
      "  Top-level keys: ['p', 'px_scale', 'px_r', 'px_rate', 'px_dropout', 'py_', 'log_pro_back_mean']\n",
      "\n",
      "    RNA ('px_scale'):\n",
      "      Shape: torch.Size([128, 36601])\n",
      "\n",
      "    Protein ('py_'):\n",
      "      'py_' is a dictionary. Keys: ['back_alpha', 'back_beta', 'rate_back', 'fore_scale', 'rate_fore', 'mixing', 'scale', 'r']\n",
      "\n",
      "    Protein Background ('log_pro_back_mean'):\n",
      "      Shape: torch.Size([128, 170])\n",
      "\n",
      "    Accessibility (key 'p'):\n",
      "      'p' is a tensor with shape: torch.Size([128, 298785])\n",
      "        Shape matches expected n_regions (298785). This could be your corrected ATAC data (e.g., probabilities).\n",
      "\n",
      "  --- End of detailed inspection for this batch ---\n",
      "\n",
      "Inspection finished. Review the output above to identify the correct keys and shapes for protein and ATAC.\n"
     ]
    }
   ],
   "source": [
    "# In a Jupyter Notebook cell (assuming Cell 1 for setup and model loading has been run)\n",
    "\n",
    "if 'model' not in locals() or 'adata_mvi_original' not in locals():\n",
    "    print(\"ERROR: 'model' or 'adata_mvi_original' not loaded. Please run the setup cell first.\")\n",
    "elif model.device.type != 'cuda':\n",
    "    print(\"ERROR: Model is not on CUDA device. Please move it to GPU.\")\n",
    "else:\n",
    "    print(f\"Model is on device: {model.device}. Proceeding with batch processing for inspection...\")\n",
    "\n",
    "    batch_size_inspect = 128\n",
    "    inspect_scdl = model._make_data_loader(\n",
    "        adata=adata_mvi_original,\n",
    "        shuffle=False,\n",
    "        batch_size=batch_size_inspect,\n",
    "    )\n",
    "    print(f\"DataLoader created. Will process one batch of size up to {batch_size_inspect}.\")\n",
    "\n",
    "    # Get expected dimensions for validation\n",
    "    n_proteins_expected = adata_mvi_original.obsm[\"ADT\"].shape[1]\n",
    "    n_regions_expected = (adata_mvi_original.var[\"modality\"] == \"peaks\").sum()\n",
    "    print(f\"Expected number of proteins: {n_proteins_expected}\")\n",
    "    print(f\"Expected number of regions (peaks): {n_regions_expected}\")\n",
    "\n",
    "    with torch.no_grad():\n",
    "        model.module.eval()\n",
    "        for i, tensors_cpu in enumerate(inspect_scdl):\n",
    "            print(f\"\\nProcessing batch {i+1} for inspection...\")\n",
    "            tensors_gpu = {\n",
    "                k: v.to(model.device) if isinstance(v, torch.Tensor) else v\n",
    "                for k, v in tensors_cpu.items()\n",
    "            }\n",
    "            print(\"  Tensors moved to GPU.\")\n",
    "\n",
    "            inference_kwargs = {\"n_samples\": 1}\n",
    "            inference_inputs = model.module._get_inference_input(tensors_gpu)\n",
    "            inference_outputs = model.module.inference(**inference_inputs, **inference_kwargs)\n",
    "            print(\"  Inference step complete.\")\n",
    "\n",
    "            generative_kwargs = {\"use_z_mean\": True}\n",
    "            generative_inputs = model.module._get_generative_input(tensors_gpu, inference_outputs)\n",
    "            generative_outputs_dict = model.module.generative(**generative_inputs, **generative_kwargs)\n",
    "            print(\"  Generative step complete.\")\n",
    "\n",
    "            # --- DETAILED INSPECTION ---\n",
    "            print(\"\\n  --- Inspecting generative_outputs_dict ---\")\n",
    "            print(f\"  Top-level keys: {list(generative_outputs_dict.keys())}\")\n",
    "\n",
    "            # RNA (already known)\n",
    "            if \"px_scale\" in generative_outputs_dict:\n",
    "                print(f\"\\n    RNA ('px_scale'):\")\n",
    "                print(f\"      Shape: {generative_outputs_dict['px_scale'].shape}\") # Batch x n_genes\n",
    "\n",
    "            # Protein\n",
    "            if \"py_\" in generative_outputs_dict:\n",
    "                print(f\"\\n    Protein ('py_'):\")\n",
    "                protein_output = generative_outputs_dict['py_']\n",
    "                if isinstance(protein_output, dict):\n",
    "                    print(f\"      'py_' is a dictionary. Keys: {list(protein_output.keys())}\")\n",
    "                    # Common keys for scvi-tools protein output: 'py_mean', 'py_normalized', 'y_pred'\n",
    "                    for prot_key in ['py_mean', 'py_normalized', 'y_pred', 'total_sum_mean']: # Add other potential keys if needed\n",
    "                        if prot_key in protein_output:\n",
    "                            prot_tensor_shape = protein_output[prot_key].shape\n",
    "                            print(f\"        Found sub-key '{prot_key}' with shape: {prot_tensor_shape}\")\n",
    "                            if prot_tensor_shape[1] == n_proteins_expected:\n",
    "                                print(f\"          Shape matches expected n_proteins ({n_proteins_expected}). This is likely your corrected protein data.\")\n",
    "                            else:\n",
    "                                print(f\"          WARNING: Shape {prot_tensor_shape[1]} does not match expected n_proteins ({n_proteins_expected}).\")\n",
    "                elif hasattr(protein_output, 'shape'): # If py_ is directly a tensor\n",
    "                    prot_tensor_shape = protein_output.shape\n",
    "                    print(f\"      'py_' is a tensor with shape: {prot_tensor_shape}\")\n",
    "                    if prot_tensor_shape[1] == n_proteins_expected:\n",
    "                        print(f\"        Shape matches expected n_proteins ({n_proteins_expected}). This could be your corrected protein data.\")\n",
    "                    else:\n",
    "                        print(f\"        WARNING: Shape {prot_tensor_shape[1]} does not match expected n_proteins ({n_proteins_expected}).\")\n",
    "                else:\n",
    "                    print(f\"      'py_' is of type: {type(protein_output)}\")\n",
    "            \n",
    "            if \"log_pro_back_mean\" in generative_outputs_dict:\n",
    "                 print(f\"\\n    Protein Background ('log_pro_back_mean'):\")\n",
    "                 print(f\"      Shape: {generative_outputs_dict['log_pro_back_mean'].shape}\")\n",
    "\n",
    "\n",
    "            # ATAC-seq (Accessibility)\n",
    "            if \"p\" in generative_outputs_dict: # This was the unusual key\n",
    "                print(f\"\\n    Accessibility (key 'p'):\")\n",
    "                atac_output = generative_outputs_dict['p']\n",
    "                if isinstance(atac_output, dict):\n",
    "                    print(f\"      'p' is a dictionary. Keys: {list(atac_output.keys())}\")\n",
    "                    # Common keys for scvi-tools ATAC output: 'pa_probs', 'rate'\n",
    "                    for atac_key in ['pa_probs', 'rate', 'probs']: # Add other potential keys\n",
    "                        if atac_key in atac_output:\n",
    "                            atac_tensor_shape = atac_output[atac_key].shape\n",
    "                            print(f\"        Found sub-key '{atac_key}' with shape: {atac_tensor_shape}\")\n",
    "                            if atac_tensor_shape[1] == n_regions_expected:\n",
    "                                print(f\"          Shape matches expected n_regions ({n_regions_expected}). This is likely your corrected ATAC data.\")\n",
    "                            else:\n",
    "                                print(f\"          WARNING: Shape {atac_tensor_shape[1]} does not match expected n_regions ({n_regions_expected}).\")\n",
    "                elif hasattr(atac_output, 'shape'): # If 'p' is directly a tensor\n",
    "                    atac_tensor_shape = atac_output.shape\n",
    "                    print(f\"      'p' is a tensor with shape: {atac_tensor_shape}\")\n",
    "                    if atac_tensor_shape[1] == n_regions_expected:\n",
    "                        print(f\"        Shape matches expected n_regions ({n_regions_expected}). This could be your corrected ATAC data (e.g., probabilities).\")\n",
    "                    else:\n",
    "                        print(f\"        WARNING: Shape {atac_tensor_shape[1]} does not match expected n_regions ({n_regions_expected}).\")\n",
    "\n",
    "                else:\n",
    "                    print(f\"      'p' is of type: {type(atac_output)}\")\n",
    "            \n",
    "            print(\"\\n  --- End of detailed inspection for this batch ---\")\n",
    "            break # Process only the first batch\n",
    "\n",
    "    print(\"\\nInspection finished. Review the output above to identify the correct keys and shapes for protein and ATAC.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cee2af9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scvi-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
