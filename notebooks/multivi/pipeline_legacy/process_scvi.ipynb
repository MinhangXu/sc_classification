{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ec07c086",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scvi\n",
    "import torch\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scanpy as sc\n",
    "import anndata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "13c37b3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "8\n",
      "11.8\n"
     ]
    }
   ],
   "source": [
    "# import torch\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.device_count())\n",
    "print(torch.version.cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2e764431",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Changed scvi.settings.dl_num_workers to: 20\n"
     ]
    }
   ],
   "source": [
    "scvi.settings.dl_num_workers = 20\n",
    "print(f\"Changed scvi.settings.dl_num_workers to: {scvi.settings.dl_num_workers}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d5f4059f",
   "metadata": {},
   "outputs": [],
   "source": [
    "scvi_model_dir = '/home/minhang/mds_project/data/cohort_adata/multiVI_model'\n",
    "adata_path= '/home/minhang/mds_project/data/cohort_adata/multiVI_model/adata.h5ad'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "36f1abe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata_mvi = sc.read_h5ad(adata_path)\n",
    "# adata_dummy = sc.read_h5ad(adata_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e07171a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(192149, 170)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adata_mvi.obsm['ADT'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "71a34305",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "modality\n",
       "peaks              298785\n",
       "Gene Expression     36601\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adata_mvi.var['modality'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c10686dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature counts by modality:\n",
      "modality\n",
      "peaks              298785\n",
      "Gene Expression     36601\n",
      "Name: count, dtype: int64\n",
      "Shape of adata_mvi: (192149, 335386)\n",
      "Shape of ADT in obsm: (192149, 170)\n",
      "Batch key 'Tech' categories: ['Multi', 'CITE']\n",
      "Categorical covariate 'sample' categories: ['P01_preSCT', 'P01_Relapse', 'P01_MRD_2', 'P01_Relapse_2', 'P01_preSCT_2', 'P02_Relapse_2', 'P02_preSCT_2', 'P02_Relapse_1', 'P03_MRD_1', 'P02_MRD_1', 'P01_MRD_1', 'P02_preSCT_1', 'P02_Relapse_4', 'P02_Relapse_3', 'P03_Relapse', 'P04_Relapse', 'P04_preSCT_2', 'P04_preSCT_1', 'P05_Relapse', 'P05_preSCT', 'unknown_unknown', 'P06_preSCT_1', 'P06_preSCT_2', 'P10_preSCT', 'P07_Relapse', 'P07_preSCT_2', 'P08_preSCT_2', 'P11_preSCT', 'P08_preSCT_1', 'P08_Relapse', 'P09_preSCT_2', 'P09_preSCT_1', 'P12_preSCT', 'P09_Relapse', 'P03_MRD_2', 'P02_MRD_2', 'P05_MRD', 'P04_MRD', 'P06_MRD', 'P11_MRD', 'P07_MRD', 'P10_MRD', 'P12_MRD', 'P09_MRD', 'P08_MRD', 'P13_MRD', 'P09_MRD_2', 'P09_MRD_3', 'P09_MRD_4', 'P13_Relapse_2', 'P13_preSCT_1', 'P13_Relapse_1', 'P13_preSCT_2']\n"
     ]
    }
   ],
   "source": [
    "# Ensure the var names are unique if not already\n",
    "adata_mvi.var_names_make_unique()\n",
    "\n",
    "# Display feature counts to verify\n",
    "print(\"Feature counts by modality:\")\n",
    "if \"modality\" in adata_mvi.var.columns:\n",
    "    print(adata_mvi.var[\"modality\"].value_counts())\n",
    "else:\n",
    "    print(\"Warning: adata_mvi.var['modality'] column not found. Ensure features are correctly ordered or n_genes/n_regions/n_proteins are specified correctly.\")\n",
    "\n",
    "print(f\"Shape of adata_mvi: {adata_mvi.shape}\")\n",
    "if \"ADT\" in adata_mvi.obsm_keys():\n",
    "    print(f\"Shape of ADT in obsm: {adata_mvi.obsm['ADT'].shape}\")\n",
    "if \"Tech\" in adata_mvi.obs.columns:\n",
    "    print(f\"Batch key 'Tech' categories: {adata_mvi.obs['Tech'].unique().tolist()}\")\n",
    "if \"sample\" in adata_mvi.obs.columns:\n",
    "    print(f\"Categorical covariate 'sample' categories: {adata_mvi.obs['sample'].unique().tolist()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4d5d0b1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mINFO    \u001b[0m Using column names from columns of adata.obsm\u001b[1m[\u001b[0m\u001b[32m'ADT'\u001b[0m\u001b[1m]\u001b[0m                                                      \n"
     ]
    }
   ],
   "source": [
    "scvi.model.MULTIVI.setup_anndata(\n",
    "    adata_mvi,\n",
    "    batch_key=\"Tech\",  # From collaborator's script\n",
    "    protein_expression_obsm_key=\"ADT\", # From collaborator's script\n",
    "    categorical_covariate_keys=[\"sample\"] # From collaborator's script\n",
    "    # Ensure your adata_mvi.X or specified layers for RNA/ATAC contain raw counts\n",
    "    # rna_layer=\"counts\", # Or whatever layer has raw RNA counts if .X is not it\n",
    "    # accessibility_layer=\"counts\", # Or whatever layer has raw ATAC counts\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "438b977e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nscvi.model.MULTIVI.setup_anndata(\\n    adata_dummy,\\n    #batch_key=\"Tech\",  # From collaborator\\'s script\\n    protein_expression_obsm_key=\"ADT\" # From collaborator\\'s script\\n    #categorical_covariate_keys=[\"sample\"] # From collaborator\\'s script\\n    # Ensure your adata_mvi.X or specified layers for RNA/ATAC contain raw counts\\n    # rna_layer=\"counts\", # Or whatever layer has raw RNA counts if .X is not it\\n    # accessibility_layer=\"counts\", # Or whatever layer has raw ATAC counts\\n)\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "scvi.model.MULTIVI.setup_anndata(\n",
    "    adata_dummy,\n",
    "    #batch_key=\"Tech\",  # From collaborator's script\n",
    "    protein_expression_obsm_key=\"ADT\" # From collaborator's script\n",
    "    #categorical_covariate_keys=[\"sample\"] # From collaborator's script\n",
    "    # Ensure your adata_mvi.X or specified layers for RNA/ATAC contain raw counts\n",
    "    # rna_layer=\"counts\", # Or whatever layer has raw RNA counts if .X is not it\n",
    "    # accessibility_layer=\"counts\", # Or whatever layer has raw ATAC counts\n",
    ")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d9a48861",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using n_genes: 36601, n_regions: 298785, n_proteins: 170\n",
      "MultiVI model shell created with specified parameters.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">MultiVI Model with the following params: \n",
       "n_genes: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">36601</span>, n_regions: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">298785</span>, n_proteins: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">170</span>, n_hidden: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">546</span>, n_latent: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">23</span>, n_layers_encoder: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>, \n",
       "n_layers_decoder: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>, dropout_rate: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1</span>, latent_distribution: normal, deep injection: <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>, gene_likelihood: zinb, \n",
       "gene_dispersion:gene, Mod.Weights: equal, Mod.Penalty: Jeffreys, protein_dispersion: protein\n",
       "Training status: Not Trained\n",
       "</pre>\n"
      ],
      "text/plain": [
       "MultiVI Model with the following params: \n",
       "n_genes: \u001b[1;36m36601\u001b[0m, n_regions: \u001b[1;36m298785\u001b[0m, n_proteins: \u001b[1;36m170\u001b[0m, n_hidden: \u001b[1;36m546\u001b[0m, n_latent: \u001b[1;36m23\u001b[0m, n_layers_encoder: \u001b[1;36m2\u001b[0m, \n",
       "n_layers_decoder: \u001b[1;36m2\u001b[0m, dropout_rate: \u001b[1;36m0.1\u001b[0m, latent_distribution: normal, deep injection: \u001b[3;91mFalse\u001b[0m, gene_likelihood: zinb, \n",
       "gene_dispersion:gene, Mod.Weights: equal, Mod.Penalty: Jeffreys, protein_dispersion: protein\n",
       "Training status: Not Trained\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Parameters from your successful CPU load in collaborator's environment\n",
    "n_genes_val = (adata_mvi.var[\"modality\"] == \"Gene Expression\").sum() if \"modality\" in adata_mvi.var.columns else 36601\n",
    "n_regions_val = (adata_mvi.var[\"modality\"] == \"peaks\").sum() if \"modality\" in adata_mvi.var.columns else 298785 # Ensure 'peaks' matches your adata_mvi.var['modality'] value for accessibility\n",
    "n_proteins_val = adata_mvi.obsm[\"ADT\"].shape[1] if \"ADT\" in adata_mvi.obsm_keys() else 170 # Inferred from ADT data typically\n",
    "\n",
    "print(f\"Using n_genes: {n_genes_val}, n_regions: {n_regions_val}, n_proteins: {n_proteins_val}\")\n",
    "'''\n",
    "model_shell = scvi.model.MULTIVI(\n",
    "    adata_mvi, # adata_mvi already has setup_anndata called on it\n",
    "    n_genes=n_genes_val,\n",
    "    n_regions=n_regions_val,\n",
    "    # n_proteins=n_proteins_val, # REMOVE THIS LINE\n",
    "    n_hidden=546,\n",
    "    n_latent=23,\n",
    "    n_layers_encoder=2,\n",
    "    n_layers_decoder=2,\n",
    "    dropout_rate=0.1,\n",
    "    latent_distribution='normal',\n",
    "    gene_likelihood='zinb',\n",
    "    dispersion='gene'\n",
    ")\n",
    "'''\n",
    "model_shell = scvi.model.MULTIVI(\n",
    "    adata_mvi, # adata_mvi already has setup_anndata called on it\n",
    "    n_genes=n_genes_val,\n",
    "    n_regions=n_regions_val,\n",
    "    # n_proteins=n_proteins_val, # This is fine, it gets inferred if protein_expression_obsm_key is set\n",
    "    # Ensure these match the training script, if defaults were used, OMIT them:\n",
    "    # n_hidden=256, # Example: default\n",
    "    # n_latent=30,  # Example: default\n",
    "    # n_layers_encoder=1, # Example: default\n",
    "    # n_layers_decoder=1, # Example: default\n",
    "    # dropout_rate=0.1, # Or training default\n",
    "    # latent_distribution='normal', # Or training default\n",
    "    # gene_likelihood='nb', # Or training default (zinb is also common)\n",
    "    # dispersion='gene' # Or training default\n",
    ")\n",
    "\n",
    "print(\"MultiVI model shell created with specified parameters.\")\n",
    "print(model_shell) # Verify the parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1976cebd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading file from: /home/minhang/mds_project/data/cohort_adata/multiVI_model/model.pt\n",
      "File loaded successfully as a dictionary.\n",
      "Top-level keys in loaded file: ['model_state_dict', 'var_names', 'attr_dict']\n",
      "Extracted 'model_state_dict'. First 5 keys: ['px_r', 'region_factors', 'background_pro_alpha', 'background_pro_log_beta', 'py_r']\n",
      "First 5 keys from model_shell.module.state_dict(): ['px_r', 'region_factors', 'background_pro_alpha', 'background_pro_log_beta', 'py_r']\n",
      "State_dict loaded into model_shell.module successfully!\n",
      "dict_keys(['model_state_dict', 'var_names', 'attr_dict'])\n"
     ]
    }
   ],
   "source": [
    "scvi_model_dir = '/home/minhang/mds_project/data/cohort_adata/multiVI_model'\n",
    "model_pt_path = os.path.join(scvi_model_dir, 'model.pt')\n",
    "\n",
    "print(f\"Loading file from: {model_pt_path}\")\n",
    "# Load the dictionary, allowing unsafe unpickling\n",
    "loaded_full_checkpoint = torch.load(model_pt_path, map_location='cpu', weights_only=False)\n",
    "print(\"File loaded successfully as a dictionary.\")\n",
    "print(\"Top-level keys in loaded file:\", list(loaded_full_checkpoint.keys()))\n",
    "\n",
    "# Extract the actual model state dictionary\n",
    "actual_state_dict = loaded_full_checkpoint['model_state_dict']\n",
    "print(\"Extracted 'model_state_dict'. First 5 keys:\", list(actual_state_dict.keys())[:5])\n",
    "\n",
    "# Compare with what your model_shell.module expects\n",
    "print(\"First 5 keys from model_shell.module.state_dict():\", list(model_shell.module.state_dict().keys())[:5])\n",
    "\n",
    "# Load the actual state dictionary into the model's module\n",
    "model_shell.module.load_state_dict(actual_state_dict) # Use the extracted dict\n",
    "model_shell.is_trained_ = True  # Manually mark the model as trained\n",
    "\n",
    "print(\"State_dict loaded into model_shell.module successfully!\")\n",
    "model = model_shell # Now 'model' is your loaded, trained model\n",
    "\n",
    "# print the loaded_full_checkpoint keys revealing that there are more than just the model_state_dict\n",
    "print(loaded_full_checkpoint.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8781890d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moving model to GPU 0...\n",
      "Model is now on device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    print(f\"Moving model to GPU 0...\")\n",
    "    model.to_device(\"cuda:0\") # Or simply \"cuda\"\n",
    "    print(f\"Model is now on device: {model.device}\")\n",
    "else:\n",
    "    print(\"CUDA not available. Model remains on CPU.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efa0973d",
   "metadata": {},
   "source": [
    "#### Debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "07a1a586",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model's own device: cuda:0\n",
      "Type of model.device: <class 'torch.device'>\n",
      "Model.device.type: cuda\n",
      "Current scvi.settings.dl_num_workers: 20\n"
     ]
    }
   ],
   "source": [
    "# Right before you create temp_loader in your debugging script:\n",
    "print(f\"Model's own device: {model.device}\")\n",
    "print(f\"Type of model.device: {type(model.device)}\")\n",
    "if isinstance(model.device, torch.device):\n",
    "    print(f\"Model.device.type: {model.device.type}\")\n",
    "else:\n",
    "    print(\"model.device is NOT a torch.device object!\")\n",
    "\n",
    "print(f\"Current scvi.settings.dl_num_workers: {scvi.settings.dl_num_workers}\")\n",
    "# ... then create temp_loader and print its pin_memory and tensor devices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "12c50286",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mINFO    \u001b[0m AnnData object appears to be a copy. Attempting to transfer setup.                                        \n",
      "\u001b[34mINFO    \u001b[0m Found batches with missing protein expression                                                             \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Manually fetching and moving tensors for a test batch:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/minhang/miniconda3/envs/scvi-env/lib/python3.12/site-packages/scvi/data/fields/_arraylike_field.py:410: UserWarning: Category 4 in adata.obs['sample'] has fewer than 3 cells. Models may not train properly.\n",
      "  mapping = _make_column_categorical(df, key, key, categorical_dtype=categorical_dtype)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Manually moved tensors. Devices:\n",
      "    Key: X, Device: cuda:0\n",
      "    Key: batch, Device: cuda:0\n",
      "    Key: extra_categorical_covs, Device: cuda:0\n",
      "    Key: ind_x, Device: cuda:0\n",
      "    Key: labels, Device: cuda:0\n",
      "    Key: proteins, Device: cuda:0\n",
      "Calling model.module.forward with manually moved GPU tensors...\n",
      "model.module.forward-like calls succeeded with manually moved tensors.\n"
     ]
    }
   ],
   "source": [
    "# model is on GPU, model.is_trained_ is True\n",
    "# THIS IS FOR DEBUGGING ONLY to see if manual movement helps isolate the issue\n",
    "\n",
    "adata_subset = adata_mvi[np.arange(min(5, adata_mvi.n_obs))].copy() # Small subset\n",
    "\n",
    "# Re-run setup_anndata on this subset if you are not using model.adata\n",
    "# scvi.model.MULTIVI.setup_anndata(adata_subset, batch_key=\"Tech\", protein_expression_obsm_key=\"ADT\", categorical_covariate_keys=[\"sample\"])\n",
    "\n",
    "# Ensure the subset is registered with the model if you pass adata_subset to get_normalized_expression\n",
    "# Or, just rely on model.adata for the main call.\n",
    "\n",
    "# For this test, let's mimic the direct data loader usage:\n",
    "scdl = model._make_data_loader(\n",
    "    adata=adata_subset, # Or model.adata_manager.adata for a subset of the original\n",
    "    indices=np.arange(adata_subset.n_obs), # Or indices_for_test\n",
    "    batch_size=adata_subset.n_obs\n",
    ")\n",
    "\n",
    "print(\"Manually fetching and moving tensors for a test batch:\")\n",
    "for tensors_cpu in scdl: # These will be on CPU\n",
    "    tensors_gpu = {\n",
    "        k: v.to(model.device) if isinstance(v, torch.Tensor) else v\n",
    "        for k, v in tensors_cpu.items()\n",
    "    }\n",
    "    print(\"Manually moved tensors. Devices:\")\n",
    "    for k, v_tensor in tensors_gpu.items():\n",
    "        if isinstance(v_tensor, torch.Tensor):\n",
    "            print(f\"    Key: {k}, Device: {v_tensor.device}\")\n",
    "\n",
    "    try:\n",
    "        print(\"Calling model.module.forward with manually moved GPU tensors...\")\n",
    "        # This is roughly what get_normalized_expression does internally\n",
    "        with torch.no_grad():\n",
    "            model.module.eval() # Ensure eval mode\n",
    "            # Note: _get_generative_input might be needed if directly calling generative\n",
    "            # We call forward, which then calls inference and generative\n",
    "            inference_inputs = model.module._get_inference_input(tensors_gpu)\n",
    "            inference_outputs = model.module.inference(**inference_inputs, n_samples=1) # n_samples from get_normalized_expression default\n",
    "            generative_inputs = model.module._get_generative_input(tensors_gpu, inference_outputs)\n",
    "            px = model.module.generative(**generative_inputs) # generative_outputs is px in MULTIVAE\n",
    "\n",
    "        print(\"model.module.forward-like calls succeeded with manually moved tensors.\")\n",
    "        # px['px_scale'] would be the normalized expression for the RNA part\n",
    "        # print(px['px_scale'].shape)\n",
    "        break # Just do one batch for this test\n",
    "    except RuntimeError as e:\n",
    "        print(f\"Error even with manually moved tensors: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eca53f31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model's own device: cuda:0\n",
      "Current scvi.settings.dl_num_workers: 2\n",
      "Successfully created temp_loader.\n",
      "  temp_loader.pin_memory (AnnDataLoader's actual pin_memory setting): False\n",
      "\n",
      "--- Tensors from AnnDataLoader (first batch) ---\n",
      "    Key: X, Device: cpu, Dtype: torch.float32, Shape: torch.Size([5, 335386])\n",
      "    Key: batch, Device: cpu, Dtype: torch.int64, Shape: torch.Size([5, 1])\n",
      "    Key: extra_categorical_covs, Device: cpu, Dtype: torch.int64, Shape: torch.Size([5, 1])\n",
      "    Key: ind_x, Device: cpu, Dtype: torch.int64, Shape: torch.Size([5, 1])\n",
      "    Key: labels, Device: cpu, Dtype: torch.int64, Shape: torch.Size([5, 1])\n",
      "    Key: proteins, Device: cpu, Dtype: torch.float32, Shape: torch.Size([5, 170])\n",
      "--------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Debugging block (modified slightly to avoid the AttributeError)\n",
    "print(f\"Model's own device: {model.device}\")\n",
    "print(f\"Current scvi.settings.dl_num_workers: {scvi.settings.dl_num_workers}\") # Verify it's 2\n",
    "\n",
    "if model.adata is not None and hasattr(model, 'adata_manager') and model.adata_manager is not None:\n",
    "    indices_subset = np.arange(min(5, model.adata.n_obs))\n",
    "    model_adata_manager = model.adata_manager\n",
    "\n",
    "    num_workers_for_loader = scvi.settings.dl_num_workers # Use the new global setting\n",
    "\n",
    "    try:\n",
    "        temp_loader = model._make_data_loader(\n",
    "            adata=model_adata_manager.adata,\n",
    "            indices=indices_subset,\n",
    "            batch_size=len(indices_subset),\n",
    "            num_workers=num_workers_for_loader\n",
    "        )\n",
    "        print(f\"Successfully created temp_loader.\")\n",
    "        print(f\"  temp_loader.pin_memory (AnnDataLoader's actual pin_memory setting): {temp_loader.pin_memory}\") # Should now be True\n",
    "\n",
    "        test_tensors_batch = next(iter(temp_loader))\n",
    "        print(\"\\n--- Tensors from AnnDataLoader (first batch) ---\")\n",
    "        for k, v_tensor in test_tensors_batch.items():\n",
    "            if isinstance(v_tensor, torch.Tensor):\n",
    "                print(f\"    Key: {k}, Device: {v_tensor.device}, Dtype: {v_tensor.dtype}, Shape: {v_tensor.shape}\")\n",
    "        print(\"--------------------------------------------------\\n\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error creating or iterating temp_loader: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "else:\n",
    "    print(\"model.adata or model.adata_manager is not properly set up for temp_loader check.\")\n",
    "\n",
    "# Then, if the tensors are on GPU, try model.get_normalized_expression(...) again\n",
    "# ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4b0a636",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model device for DataLoader check: cuda:0\n",
      "Successfully created temp_loader.\n",
      "\n",
      "--- Tensors from AnnDataLoader (first batch) ---\n",
      "  Key: X, Device: cpu, Dtype: torch.float32, Shape: torch.Size([5, 335386])\n",
      "  Key: batch, Device: cpu, Dtype: torch.int64, Shape: torch.Size([5, 1])\n",
      "  Key: extra_categorical_covs, Device: cpu, Dtype: torch.int64, Shape: torch.Size([5, 1])\n",
      "  Key: ind_x, Device: cpu, Dtype: torch.int64, Shape: torch.Size([5, 1])\n",
      "  Key: labels, Device: cpu, Dtype: torch.int64, Shape: torch.Size([5, 1])\n",
      "  Key: proteins, Device: cpu, Dtype: torch.float32, Shape: torch.Size([5, 170])\n",
      "--------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Debugging block for temp_loader:\n",
    "print(f\"Model device for DataLoader check: {model.device}\")\n",
    "if model.adata is not None and hasattr(model, 'adata_manager') and model.adata_manager is not None:\n",
    "    indices_subset = np.arange(min(5, model.adata.n_obs)) # \n",
    "    model_adata_manager = model.adata_manager # Use the manager associated with the model instance\n",
    "    try:\n",
    "        temp_loader = model._make_data_loader(adata=model_adata_manager.adata, indices=indices_subset, batch_size=len(indices_subset))\n",
    "        print(\"Successfully created temp_loader.\")\n",
    "        test_tensors_batch = next(iter(temp_loader))\n",
    "        print(\"\\n--- Tensors from AnnDataLoader (first batch) ---\")\n",
    "        for k, v_tensor in test_tensors_batch.items():\n",
    "            if isinstance(v_tensor, torch.Tensor):\n",
    "                print(f\"  Key: {k}, Device: {v_tensor.device}, Dtype: {v_tensor.dtype}, Shape: {v_tensor.shape}\")\n",
    "            else:\n",
    "                print(f\"  Key: {k}, Type: {type(v_tensor)}\")\n",
    "        print(\"--------------------------------------------------\\n\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error creating or iterating temp_loader: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "else:\n",
    "    print(\"model.adata or model.adata_manager is not properly set up for temp_loader check.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bbc70172",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model device for latent space generation: cuda:0\n",
      "Attempting model.get_latent_representation()...\n",
      "model.get_latent_representation() failed: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument mat1 in method wrapper_CUDA_addmm)\n",
      "Attempting manual latent space generation loop as a fallback...\n"
     ]
    }
   ],
   "source": [
    "print(f\"Model device for latent space generation: {model.device}\")\n",
    "\n",
    "# Option A: Try the standard method first (might fail due to DataLoader issues)\n",
    "try:\n",
    "    print(\"Attempting model.get_latent_representation()...\")\n",
    "    adata_mvi.obsm['X_multivi'] = model.get_latent_representation(adata_mvi)\n",
    "    print(\"Successfully obtained latent representation using model.get_latent_representation().\")\n",
    "    print(f\"Shape of X_multivi: {adata_mvi.obsm['X_multivi'].shape}\")\n",
    "except Exception as e:\n",
    "    print(f\"model.get_latent_representation() failed: {e}\")\n",
    "    print(\"Attempting manual latent space generation loop as a fallback...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "77e0497a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempting to get normalized expression...\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument mat1 in method wrapper_CUDA_addmm)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mAttempting to get normalized expression...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m# If your model was saved with an anndata, it might be accessible via model.adata\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# If you used adata=None with load, it should have tried to load it from the model_dir.\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# When manually constructing, the adata_mvi you used for setup is registered.\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m norm_exp = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_normalized_expression\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43madata\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# Or use None if the model has adata_mvi registered internally from the constructor\u001b[39;49;00m\n\u001b[32m      7\u001b[39m \u001b[43m    \u001b[49m\u001b[43mn_samples\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m5\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# Small number for testing\u001b[39;49;00m\n\u001b[32m      8\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mNormalized expression retrieved successfully!\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     10\u001b[39m \u001b[38;5;28mprint\u001b[39m(norm_exp.shape)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/scvi-env/lib/python3.12/site-packages/torch/utils/_contextlib.py:116\u001b[39m, in \u001b[36mcontext_decorator.<locals>.decorate_context\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    113\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m    114\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecorate_context\u001b[39m(*args, **kwargs):\n\u001b[32m    115\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[32m--> \u001b[39m\u001b[32m116\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/scvi-env/lib/python3.12/site-packages/scvi/model/_multivi.py:672\u001b[39m, in \u001b[36mMULTIVI.get_normalized_expression\u001b[39m\u001b[34m(self, adata, indices, n_samples_overall, transform_batch, gene_list, use_z_mean, n_samples, batch_size, return_mean, return_numpy)\u001b[39m\n\u001b[32m    670\u001b[39m     batch_indices = tensors[REGISTRY_KEYS.BATCH_KEY]\n\u001b[32m    671\u001b[39m     tensors[REGISTRY_KEYS.BATCH_KEY] = torch.ones_like(batch_indices) * batch\n\u001b[32m--> \u001b[39m\u001b[32m672\u001b[39m _, generative_outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m.\u001b[49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    673\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    674\u001b[39m \u001b[43m    \u001b[49m\u001b[43minference_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mn_samples\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_samples\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    675\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgenerative_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43muse_z_mean\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_z_mean\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    676\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompute_loss\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    677\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    678\u001b[39m output = generative_outputs[\u001b[33m\"\u001b[39m\u001b[33mpx_scale\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m    679\u001b[39m output = output[..., gene_mask]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/scvi-env/lib/python3.12/site-packages/scvi/module/base/_decorators.py:32\u001b[39m, in \u001b[36mauto_move_data.<locals>.auto_transfer_args\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     30\u001b[39m \u001b[38;5;66;03m# decorator only necessary after training\u001b[39;00m\n\u001b[32m     31\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.training:\n\u001b[32m---> \u001b[39m\u001b[32m32\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     34\u001b[39m device = \u001b[38;5;28mlist\u001b[39m({p.device \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.parameters()})\n\u001b[32m     35\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(device) > \u001b[32m1\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/scvi-env/lib/python3.12/site-packages/scvi/module/base/_base_module.py:208\u001b[39m, in \u001b[36mBaseModuleClass.forward\u001b[39m\u001b[34m(self, tensors, get_inference_input_kwargs, get_generative_input_kwargs, inference_kwargs, generative_kwargs, loss_kwargs, compute_loss)\u001b[39m\n\u001b[32m    177\u001b[39m \u001b[38;5;129m@auto_move_data\u001b[39m\n\u001b[32m    178\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\n\u001b[32m    179\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    186\u001b[39m     compute_loss=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m    187\u001b[39m ) -> \u001b[38;5;28mtuple\u001b[39m[torch.Tensor, torch.Tensor] | \u001b[38;5;28mtuple\u001b[39m[torch.Tensor, torch.Tensor, LossOutput]:\n\u001b[32m    188\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Forward pass through the network.\u001b[39;00m\n\u001b[32m    189\u001b[39m \n\u001b[32m    190\u001b[39m \u001b[33;03m    Parameters\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    206\u001b[39m \u001b[33;03m        another return value.\u001b[39;00m\n\u001b[32m    207\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m208\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_generic_forward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    209\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    210\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    211\u001b[39m \u001b[43m        \u001b[49m\u001b[43minference_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    212\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgenerative_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    213\u001b[39m \u001b[43m        \u001b[49m\u001b[43mloss_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    214\u001b[39m \u001b[43m        \u001b[49m\u001b[43mget_inference_input_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    215\u001b[39m \u001b[43m        \u001b[49m\u001b[43mget_generative_input_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    216\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcompute_loss\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    217\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/scvi-env/lib/python3.12/site-packages/scvi/module/base/_base_module.py:748\u001b[39m, in \u001b[36m_generic_forward\u001b[39m\u001b[34m(module, tensors, inference_kwargs, generative_kwargs, loss_kwargs, get_inference_input_kwargs, get_generative_input_kwargs, compute_loss)\u001b[39m\n\u001b[32m    745\u001b[39m get_generative_input_kwargs = _get_dict_if_none(get_generative_input_kwargs)\n\u001b[32m    747\u001b[39m inference_inputs = module._get_inference_input(tensors, **get_inference_input_kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m748\u001b[39m inference_outputs = \u001b[43mmodule\u001b[49m\u001b[43m.\u001b[49m\u001b[43minference\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43minference_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43minference_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    749\u001b[39m generative_inputs = module._get_generative_input(\n\u001b[32m    750\u001b[39m     tensors, inference_outputs, **get_generative_input_kwargs\n\u001b[32m    751\u001b[39m )\n\u001b[32m    752\u001b[39m generative_outputs = module.generative(**generative_inputs, **generative_kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/scvi-env/lib/python3.12/site-packages/scvi/module/base/_decorators.py:32\u001b[39m, in \u001b[36mauto_move_data.<locals>.auto_transfer_args\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     30\u001b[39m \u001b[38;5;66;03m# decorator only necessary after training\u001b[39;00m\n\u001b[32m     31\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.training:\n\u001b[32m---> \u001b[39m\u001b[32m32\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     34\u001b[39m device = \u001b[38;5;28mlist\u001b[39m({p.device \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.parameters()})\n\u001b[32m     35\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(device) > \u001b[32m1\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/scvi-env/lib/python3.12/site-packages/scvi/module/_multivae.py:599\u001b[39m, in \u001b[36mMULTIVAE.inference\u001b[39m\u001b[34m(self, x, y, batch_index, cont_covs, cat_covs, label, cell_idx, n_samples)\u001b[39m\n\u001b[32m    596\u001b[39m     categorical_input = ()\n\u001b[32m    598\u001b[39m \u001b[38;5;66;03m# Z Encoders\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m599\u001b[39m qzm_acc, qzv_acc, z_acc = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mz_encoder_accessibility\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    600\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoder_input_accessibility\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43mcategorical_input\u001b[49m\n\u001b[32m    601\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    602\u001b[39m qzm_expr, qzv_expr, z_expr = \u001b[38;5;28mself\u001b[39m.z_encoder_expression(\n\u001b[32m    603\u001b[39m     encoder_input_expression, batch_index, *categorical_input\n\u001b[32m    604\u001b[39m )\n\u001b[32m    605\u001b[39m qzm_pro, qzv_pro, z_pro = \u001b[38;5;28mself\u001b[39m.z_encoder_protein(\n\u001b[32m    606\u001b[39m     encoder_input_protein, batch_index, *categorical_input\n\u001b[32m    607\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/scvi-env/lib/python3.12/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/scvi-env/lib/python3.12/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/scvi-env/lib/python3.12/site-packages/scvi/nn/_base_components.py:283\u001b[39m, in \u001b[36mEncoder.forward\u001b[39m\u001b[34m(self, x, *cat_list)\u001b[39m\n\u001b[32m    262\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"The forward computation for a single sample.\u001b[39;00m\n\u001b[32m    263\u001b[39m \n\u001b[32m    264\u001b[39m \u001b[33;03m #. Encodes the data into latent space using the encoder network\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    280\u001b[39m \n\u001b[32m    281\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    282\u001b[39m \u001b[38;5;66;03m# Parameters for latent distribution\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m283\u001b[39m q = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43mcat_list\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    284\u001b[39m q_m = \u001b[38;5;28mself\u001b[39m.mean_encoder(q)\n\u001b[32m    285\u001b[39m q_v = \u001b[38;5;28mself\u001b[39m.var_activation(\u001b[38;5;28mself\u001b[39m.var_encoder(q)) + \u001b[38;5;28mself\u001b[39m.var_eps\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/scvi-env/lib/python3.12/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/scvi-env/lib/python3.12/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/scvi-env/lib/python3.12/site-packages/scvi/nn/_base_components.py:184\u001b[39m, in \u001b[36mFCLayers.forward\u001b[39m\u001b[34m(self, x, *cat_list)\u001b[39m\n\u001b[32m    182\u001b[39m                         one_hot_cat_list_layer = one_hot_cat_list\n\u001b[32m    183\u001b[39m                     x = torch.cat((x, *one_hot_cat_list_layer), dim=-\u001b[32m1\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m184\u001b[39m                 x = \u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    185\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/scvi-env/lib/python3.12/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/scvi-env/lib/python3.12/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/scvi-env/lib/python3.12/site-packages/torch/nn/modules/linear.py:125\u001b[39m, in \u001b[36mLinear.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    124\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) -> Tensor:\n\u001b[32m--> \u001b[39m\u001b[32m125\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mRuntimeError\u001b[39m: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument mat1 in method wrapper_CUDA_addmm)"
     ]
    }
   ],
   "source": [
    "print(\"Attempting to get normalized expression...\")\n",
    "# If your model was saved with an anndata, it might be accessible via model.adata\n",
    "# If you used adata=None with load, it should have tried to load it from the model_dir.\n",
    "# When manually constructing, the adata_mvi you used for setup is registered.\n",
    "norm_exp = model.get_normalized_expression(\n",
    "    adata=None, # Or use None if the model has adata_mvi registered internally from the constructor\n",
    "    n_samples=5 # Small number for testing\n",
    ")\n",
    "print(\"Normalized expression retrieved successfully!\")\n",
    "print(norm_exp.shape)\n",
    "print(norm_exp.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aab3a789",
   "metadata": {},
   "source": [
    "#### After debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ad8b8dfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using scvi.settings.dl_num_workers: 2\n",
      "Processing 192149 cells in batches of 512 to get normalized expression...\n"
     ]
    }
   ],
   "source": [
    "print(f\"Using scvi.settings.dl_num_workers: {scvi.settings.dl_num_workers}\")\n",
    "\n",
    "batch_size = 512  # Adjust based on your GPU memory\n",
    "all_norm_exp_list = []\n",
    "\n",
    "# Create a DataLoader for the full AnnData object.\n",
    "# shuffle=False is CRITICAL to maintain original cell order.\n",
    "full_scdl = model._make_data_loader(\n",
    "    adata=adata_mvi, # Your full AnnData object used with the model\n",
    "    shuffle=False,\n",
    "    batch_size=batch_size,\n",
    "    # num_workers will be taken from scvi.settings.dl_num_workers\n",
    ")\n",
    "\n",
    "print(f\"Processing {adata_mvi.n_obs} cells in batches of {batch_size} to get normalized expression...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "469484bf",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 22\u001b[39m\n\u001b[32m     20\u001b[39m generative_inputs = model.module._get_generative_input(tensors_gpu, inference_outputs)\n\u001b[32m     21\u001b[39m \u001b[38;5;66;03m# The generative output from MULTIVAE contains px, py, pa\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m22\u001b[39m generative_outputs_dict = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgenerative\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mgenerative_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mgenerative_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     24\u001b[39m \u001b[38;5;66;03m# 4. Extract RNA normalized expression ('px_scale')\u001b[39;00m\n\u001b[32m     25\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mpx_scale\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m generative_outputs_dict:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/scvi-env/lib/python3.12/site-packages/scvi/module/base/_decorators.py:41\u001b[39m, in \u001b[36mauto_move_data.<locals>.auto_transfer_args\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     39\u001b[39m args = _move_data_to_device(args, device)\n\u001b[32m     40\u001b[39m kwargs = _move_data_to_device(kwargs, device)\n\u001b[32m---> \u001b[39m\u001b[32m41\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/scvi-env/lib/python3.12/site-packages/scvi/module/_multivae.py:761\u001b[39m, in \u001b[36mMULTIVAE.generative\u001b[39m\u001b[34m(self, z, qz_m, batch_index, cont_covs, cat_covs, libsize_expr, size_factor, use_z_mean, label)\u001b[39m\n\u001b[32m    758\u001b[39m px_r = torch.exp(px_r)\n\u001b[32m    760\u001b[39m \u001b[38;5;66;03m# Protein Decoder\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m761\u001b[39m py_, log_pro_back_mean = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mz_decoder_pro\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdecoder_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43mcategorical_input\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    762\u001b[39m \u001b[38;5;66;03m# Protein Dispersion\u001b[39;00m\n\u001b[32m    763\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.protein_dispersion == \u001b[33m\"\u001b[39m\u001b[33mprotein-label\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    764\u001b[39m     \u001b[38;5;66;03m# py_r gets transposed - last dimension is n_proteins\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/scvi-env/lib/python3.12/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/scvi-env/lib/python3.12/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/scvi-env/lib/python3.12/site-packages/scvi/module/_multivae.py:162\u001b[39m, in \u001b[36mDecoderADT.forward\u001b[39m\u001b[34m(self, z, *cat_list)\u001b[39m\n\u001b[32m    160\u001b[39m py_[\u001b[33m\"\u001b[39m\u001b[33mback_alpha\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[38;5;28mself\u001b[39m.py_back_mean_log_alpha(py_back_cat_z, *cat_list)\n\u001b[32m    161\u001b[39m py_[\u001b[33m\"\u001b[39m\u001b[33mback_beta\u001b[39m\u001b[33m\"\u001b[39m] = torch.exp(\u001b[38;5;28mself\u001b[39m.py_back_mean_log_beta(py_back_cat_z, *cat_list))\n\u001b[32m--> \u001b[39m\u001b[32m162\u001b[39m log_pro_back_mean = \u001b[43mNormal\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpy_\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mback_alpha\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpy_\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mback_beta\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m.rsample()\n\u001b[32m    163\u001b[39m py_[\u001b[33m\"\u001b[39m\u001b[33mrate_back\u001b[39m\u001b[33m\"\u001b[39m] = torch.exp(log_pro_back_mean)\n\u001b[32m    165\u001b[39m py_fore = \u001b[38;5;28mself\u001b[39m.py_fore_decoder(z, *cat_list)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/scvi-env/lib/python3.12/site-packages/torch/distributions/normal.py:60\u001b[39m, in \u001b[36mNormal.__init__\u001b[39m\u001b[34m(self, loc, scale, validate_args)\u001b[39m\n\u001b[32m     58\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     59\u001b[39m     batch_shape = \u001b[38;5;28mself\u001b[39m.loc.size()\n\u001b[32m---> \u001b[39m\u001b[32m60\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mbatch_shape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidate_args\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvalidate_args\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/scvi-env/lib/python3.12/site-packages/torch/distributions/distribution.py:71\u001b[39m, in \u001b[36mDistribution.__init__\u001b[39m\u001b[34m(self, batch_shape, event_shape, validate_args)\u001b[39m\n\u001b[32m     69\u001b[39m         value = \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, param)\n\u001b[32m     70\u001b[39m         valid = constraint.check(value)\n\u001b[32m---> \u001b[39m\u001b[32m71\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch._is_all_true(valid):\n\u001b[32m     72\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m     73\u001b[39m                 \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mExpected parameter \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparam\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     74\u001b[39m                 \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(value).\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m of shape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtuple\u001b[39m(value.shape)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m) \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m     77\u001b[39m                 \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mbut found invalid values:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mvalue\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m     78\u001b[39m             )\n\u001b[32m     79\u001b[39m \u001b[38;5;28msuper\u001b[39m().\u001b[34m__init__\u001b[39m()\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "with torch.no_grad(): # Ensure no gradients are computed during this inference\n",
    "    model.module.eval() # Set the underlying nn.Module to evaluation mode\n",
    "\n",
    "    for tensors_cpu in full_scdl:\n",
    "        # 1. Manually move tensors to the model's device\n",
    "        tensors_gpu = {\n",
    "            k: v.to(model.device) if isinstance(v, torch.Tensor) else v\n",
    "            for k, v in tensors_cpu.items()\n",
    "        }\n",
    "\n",
    "        # 2. Perform inference to get latent representation\n",
    "        # These kwargs are typical for getting a deterministic latent representation\n",
    "        inference_kwargs = {\"n_samples\": 1}\n",
    "        inference_inputs = model.module._get_inference_input(tensors_gpu)\n",
    "        inference_outputs = model.module.inference(**inference_inputs, **inference_kwargs)\n",
    "\n",
    "        # 3. Perform generation of normalized expression\n",
    "        # These kwargs are typical for what get_normalized_expression would aim for (mean of normalized values)\n",
    "        generative_kwargs = {\"use_z_mean\": True}\n",
    "        generative_inputs = model.module._get_generative_input(tensors_gpu, inference_outputs)\n",
    "        # The generative output from MULTIVAE contains px, py, pa\n",
    "        generative_outputs_dict = model.module.generative(**generative_inputs, **generative_kwargs)\n",
    "\n",
    "        # 4. Extract RNA normalized expression ('px_scale')\n",
    "        if \"px_scale\" in generative_outputs_dict:\n",
    "            batch_norm_exp_gpu = generative_outputs_dict[\"px_scale\"]\n",
    "            all_norm_exp_list.append(batch_norm_exp_gpu.cpu().numpy()) # Move to CPU and convert to NumPy\n",
    "        else:\n",
    "            print(f\"Warning: 'px_scale' not found in generative_outputs_dict. Available keys: {generative_outputs_dict.keys()}\")\n",
    "            # Handle this error appropriately, perhaps by breaking or logging\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e21c959c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Concatenate results and create DataFrame\n",
    "if all_norm_exp_list:\n",
    "    final_norm_exp_np = np.concatenate(all_norm_exp_list, axis=0)\n",
    "\n",
    "    # Get gene names (ensure this aligns with the model's understanding of genes)\n",
    "    # In MULTIVI, n_vars usually corresponds to n_genes.\n",
    "    # The AnnDataManager also stores the column names for the 'X' field if it was set up.\n",
    "    # model.adata_manager.get_state_registry(REGISTRY_KEYS.X_KEY).column_names\n",
    "    # However, adata_mvi.var[\"modality\"] is also a reliable source if used for setup.\n",
    "    gene_expression_mask = (adata_mvi.var[\"modality\"] == \"Gene Expression\")\n",
    "    gene_names = adata_mvi.var_names[gene_expression_mask].tolist()\n",
    "\n",
    "    if final_norm_exp_np.shape[1] == len(gene_names):\n",
    "        norm_exp_df = pd.DataFrame(\n",
    "            final_norm_exp_np,\n",
    "            index=adata_mvi.obs_names, # Assumes cells are in original order due to shuffle=False\n",
    "            columns=gene_names\n",
    "        )\n",
    "        print(\"\\nSuccessfully generated DataFrame for normalized expression:\")\n",
    "        print(norm_exp_df.head())\n",
    "\n",
    "        # Now you can use norm_exp_df for your downstream analysis\n",
    "        # For example, save it:\n",
    "        # norm_exp_df.to_csv(\"batch_corrected_normalized_expression.csv\")\n",
    "\n",
    "    else:\n",
    "        print(f\"\\nShape Mismatch Error: The number of features in the normalized expression output ({final_norm_exp_np.shape[1]})\")\n",
    "        print(f\"does not match the number of gene names derived from adata_mvi.var['modality'] ({len(gene_names)}).\")\n",
    "        print(f\"Also check against model's n_vars: {model.summary_stats.n_vars if hasattr(model, 'summary_stats') else 'N/A'}\")\n",
    "        print(\"Please verify the output keys from model.module.generative() and the gene indexing.\")\n",
    "else:\n",
    "    print(\"No normalized expression data was generated.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scvi-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
